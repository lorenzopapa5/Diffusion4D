# Diffusion4D
## D4D: An RGBD diffusion model to boost monocular depth estimation

## Train/Test Datasets:

* NYU Depth v2: [https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)
* KITTI: [https://www.cvlibs.net/datasets/kitti/](https://www.cvlibs.net/datasets/kitti/)
* DIML/CVL RGB-D: [https://dimlrgbd.github.io/](https://dimlrgbd.github.io/)
* SceneNet RGB-D: [https://robotvault.bitbucket.io/scenenet-rgbd.html](https://robotvault.bitbucket.io/scenenet-rgbd.html)
* SYNTHIA-SF: [https://synthia-dataset.net/](https://synthia-dataset.net/) 

### Generated datasets with D4D:

* D4D-NYU: [https://drive.google.com/drive/folders/D4D-NYU](https://drive.google.com/drive/folders/19H7noUL8qA6dJDp9ko0YJFv7W9LuTVM3?usp=sharing)
* D4D-KITTI: [https://drive.google.com/drive/folders/D4D-KITTI](https://drive.google.com/drive/folders/1GaEPbF8MJAYAXSH2LnT1mQJ_8KbDoYKP?usp=sharing)

WORK-IN-PROGRESS
